{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "def sigmoid (x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "class Neuron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "    def feedforward(self, inputs):\n",
        "        total = np.dot(self.weights, inputs)+self.bias\n",
        "        return sigmoid(total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8151036049051821\n",
            "(0.7216325609518421, 0.7216325609518421)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Задание 1.1.3 Р/т №7\"\"\"\n",
        "\n",
        "class TripleInputNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        weights = np.array([0.5, 0.5, 0.5])\n",
        "        bias =0\n",
        "        self.h1 = Neuron(weights=weights, bias=bias)\n",
        "        self.h2 = Neuron(weights=weights, bias=bias)\n",
        "        self.h3 = Neuron(weights=weights, bias=bias)\n",
        "        self.o1 = Neuron(weights=weights, bias=bias)\n",
        "    def feedforwards(self, x):\n",
        "        out_h1=self.h1.feedforward(x)\n",
        "        out_h2=self.h2.feedforward(x)\n",
        "        out_h3=self.h3.feedforward(x)\n",
        "        out_o1=self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
        "        return out_o1\n",
        "\n",
        "network = TripleInputNeuralNetwork()\n",
        "x=np.array([2,3,4])\n",
        "print(network.feedforwards(x))\n",
        "\n",
        "class DoubleInputNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        weights = np.array([0,1])\n",
        "        bias =0\n",
        "        self.h1 = Neuron(weights=weights, bias=bias)\n",
        "        self.h2 = Neuron(weights=weights, bias=bias)\n",
        "        self.o1 = Neuron(weights=weights, bias=bias)\n",
        "        self.o2 = Neuron(weights=weights, bias=bias)\n",
        "    def feedforwards(self, x):\n",
        "        out_h1=self.h1.feedforward(x)\n",
        "        out_h2=self.h2.feedforward(x)\n",
        "        out_o1=self.o1.feedforward(np.array([out_h1, out_h2]))\n",
        "        out_o2=self.o2.feedforward(np.array([out_h1, out_h2]))\n",
        "        return out_o1, out_o2\n",
        "\n",
        "network = DoubleInputNeuralNetwork()\n",
        "x=np.array([2,3])\n",
        "print(network.feedforwards(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9050813365686774\n",
            "0.9050813365686774\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Задание 1.1.4 Р/т №7\"\"\"\n",
        "\n",
        "def tanh (x):\n",
        "    return math.tanh(x)\n",
        "class TanhNeuron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "    def feedforward(self, inputs):\n",
        "        total = np.dot(self.weights, inputs)+self.bias\n",
        "        return tanh(total)\n",
        "class TanhTripleInputNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        weights = np.array([0.5, 0.5, 0.5])\n",
        "        bias =0\n",
        "        self.h1 = TanhNeuron(weights=weights, bias=bias)\n",
        "        self.h2 = TanhNeuron(weights=weights, bias=bias)\n",
        "        self.h3 = TanhNeuron(weights=weights, bias=bias)\n",
        "        self.o1 = TanhNeuron(weights=weights, bias=bias)\n",
        "    def feedforwards(self, x):\n",
        "        out_h1=self.h1.feedforward(x)\n",
        "        out_h2=self.h2.feedforward(x)\n",
        "        out_h3=self.h3.feedforward(x)\n",
        "        out_o1=self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
        "        return out_o1\n",
        "    \n",
        "network1 = TanhTripleInputNeuralNetwork()\n",
        "x=np.array([2,3,4])\n",
        "print(network1.feedforwards(x))\n",
        "\n",
        "def relumax (x):\n",
        "    return max(0, x)\n",
        "class RelUNeuron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "    def feedforward(self, inputs):\n",
        "        total = np.dot(self.weights, inputs)+self.bias\n",
        "        return tanh(total)\n",
        "class ReLUTripleInputNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        weights = np.array([0.5, 0.5, 0.5])\n",
        "        bias =0\n",
        "        self.h1 = RelUNeuron(weights=weights, bias=bias)\n",
        "        self.h2 = RelUNeuron(weights=weights, bias=bias)\n",
        "        self.h3 = RelUNeuron(weights=weights, bias=bias)\n",
        "        self.o1 = RelUNeuron(weights=weights, bias=bias)\n",
        "    def feedforwards(self, x):\n",
        "        out_h1=self.h1.feedforward(x)\n",
        "        out_h2=self.h2.feedforward(x)\n",
        "        out_h3=self.h3.feedforward(x)\n",
        "        out_o1=self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
        "        return out_o1\n",
        "\n",
        "network2 = ReLUTripleInputNeuralNetwork()\n",
        "y=np.array([2,3,4])\n",
        "print(network2.feedforwards(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"Задание 1.3.1 Р/т №7\"\"\"\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np\n",
        "iris = load_iris()\n",
        "dataframe = pd.read_csv(\"https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv\")\n",
        "exp = dataframe.iloc[:, :-1].values\n",
        "salary = dataframe.iloc[:, 1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 2 1 0 2 1 0 0 1 2 0 1 2 2]\n",
            "[1 2 2 1 0 2 1 0 0 1 2 0 1 2 2]\n",
            "Test Accuracy: 0.9666666666666667\n",
            "Training Accuracy: 0.975\n",
            "Loss : 0.3012607394074939\n",
            "Number of coefs : 2\n",
            "Number of Intercept : 2\n",
            "Number of Iterations for Which Estimator Ran : 200\n",
            "Name of Output Layer Activation Function : softmax\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(iris.data, iris.target, test_size=0.20, random_state=123)\n",
        "mlp_classifier = MLPClassifier(random_state=123)\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "Y_preds = mlp_classifier.predict(X_test)\n",
        "print(Y_preds[:15])\n",
        "print(Y_test[:15])\n",
        "print(f'Test Accuracy: {mlp_classifier.score(X_test, Y_test)}')\n",
        "print(f'Training Accuracy: {mlp_classifier.score(X_train, Y_train)}')\n",
        "print(f'Loss : {mlp_classifier.loss_}')\n",
        "print(f'Number of coefs : {len(mlp_classifier.coefs_)}')\n",
        "print(f'Number of Intercept : {len(mlp_classifier.intercepts_)}')\n",
        "print(f'Number of Iterations for Which Estimator Ran : {mlp_classifier.n_iter_}')\n",
        "print(f'Name of Output Layer Activation Function : {mlp_classifier.out_activation_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20.26234628 55.2781752  18.82135812 50.48274487 20.26234628 50.9622879 ]\n",
            "[ 54445. 121872.  56642. 116969.  64445. 112635.]\n",
            "Test R^2 Accuracy: -8.796447137437891\n",
            "Training R^2 Accuracy: -8.260600732856043\n",
            "Loss : 2988058032.1601596\n",
            "Number of coefs : 2\n",
            "Number of Intercept : 2\n",
            "Number of Iterations for Which Estimator Ran : 200\n",
            "Name of Output Layer Activation Function : identity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, Y_train, Y_test=train_test_split(exp, salary, test_size=0.20, random_state=123)\n",
        "mlp_regressor = MLPRegressor(random_state=123)\n",
        "#from sklearn.linear_model import LinearRegression\n",
        "#mlp_regressor = LinearRegression() \n",
        "mlp_regressor.fit(X_train, Y_train)\n",
        "Y_preds = mlp_regressor.predict(X_test)\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])\n",
        "print(f'Test R^2 Accuracy: {mlp_regressor.score(X_test, Y_test)}')\n",
        "print(f'Training R^2 Accuracy: {mlp_regressor.score(X_train, Y_train)}')\n",
        "print(f'Loss : {mlp_regressor.loss_}')\n",
        "print(f'Number of coefs : {len(mlp_regressor.coefs_)}')\n",
        "print(f'Number of Intercept : {len(mlp_regressor.intercepts_)}')\n",
        "print(f'Number of Iterations for Which Estimator Ran : {mlp_regressor.n_iter_}')\n",
        "print(f'Name of Output Layer Activation Function : {mlp_regressor.out_activation_}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
